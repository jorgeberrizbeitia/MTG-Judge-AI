{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0f40982b",
   "metadata": {},
   "source": [
    "MTG Judge RAG\n",
    "---------------------------------------------------\n",
    "This is a simple Python script for building an AI-powered MTG rules assistant\n",
    "using Retrieval-Augmented Generation (RAG) with OpenAI + FAISS.\n",
    "\n",
    "- Loads the Comprehensive Rules from a text file.\n",
    "- Splits rules into chunks.\n",
    "- Creates embeddings with OpenAI.\n",
    "- Stores them in ChromaDB for fast search (not using FAISS due to py versioning)\n",
    "- Lets you ask questions, retrieves relevant rules, and asks the LLM to answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4fe92255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- IMPORTS --------\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import chromadb\n",
    "\n",
    "from openai import OpenAI\n",
    "# client = OpenAI(api_key=OPENAI_API_KEY)   # don’t pass api_key explicitly\n",
    "\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1f7039ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- CONFIG --------\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "EMBED_MODEL = \"text-embedding-3-large\"\n",
    "CHAT_MODEL = \"gpt-4o-mini\"\n",
    "CHROMA_DB_DIR = \"./chroma_db\"\n",
    "os.makedirs(CHROMA_DB_DIR, exist_ok=True) # to create folder if it doesn't exist\n",
    "RULES_FILE = \"./comprehensive-rules.txt\"\n",
    "CARDS_FILE = \"./clean-standard-cards.json\"\n",
    "CHUNK_SIZE = 700 # words approximation\n",
    "TOP_K = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4a9002e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -------- INITIALIZATION --------\n",
    "client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "baf4fd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- HELPER LOAD RULES --------\n",
    "def load_rules(path):\n",
    "    \"\"\"Load the MTG comprehensive rules from a text file.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Rules file not found at {path}\")\n",
    "        return []\n",
    "\n",
    "    docs = []\n",
    "    with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            # Rules usually like: 603.1. Some text\n",
    "            match = re.match(r\"^(\\d{1,3}(?:\\.\\d+)+)\\s+(.*)$\", line)\n",
    "            if match:\n",
    "                rule_id, body = match.groups()\n",
    "                docs.append({\n",
    "                    \"id\": f\"CR:{rule_id}\",\n",
    "                    \"text\": f\"{rule_id} {body}\",\n",
    "                    \"rule_id\": rule_id,\n",
    "                    \"source\": \"Comprehensive Rules\"\n",
    "                })\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cb4bbe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- HELPER LOAD CARDS --------\n",
    "def load_cards(path):\n",
    "    \"\"\"Load MTG card data from your JSON export.\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"Card file not found at {path}\")\n",
    "        return []\n",
    "\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        cards = json.load(f)\n",
    "\n",
    "    docs = []\n",
    "    for c in cards:\n",
    "        # Skip cards without names or text\n",
    "        if \"name\" not in c or not c.get(\"originalText\"):\n",
    "            continue\n",
    "\n",
    "        # Construct a searchable text block for embedding\n",
    "        text_parts = [\n",
    "            f\"Name: {c['name']}\",\n",
    "            f\"Mana Cost: {c.get('manaCost', '')}\",\n",
    "            f\"Types: {' '.join(c.get('types', []))}\",\n",
    "            f\"Subtypes: {' '.join(c.get('subtypes', []))}\",\n",
    "            f\"Abilities/Keywords: {', '.join(c.get('keywords', []))}\",\n",
    "            f\"Text: {c['originalText']}\"\n",
    "        ]\n",
    "\n",
    "        # Add rulings (big chunk but useful)\n",
    "        rulings = c.get(\"rulings\", [])\n",
    "        if rulings:\n",
    "            rulings_text = \" | \".join(r[\"text\"] for r in rulings if \"text\" in r)\n",
    "            text_parts.append(f\"Rulings: {rulings_text}\")\n",
    "\n",
    "        full_text = \"\\n\".join(text_parts)\n",
    "\n",
    "        docs.append({\n",
    "            \"id\": f\"CARD:{c['uuid']}\",   # use UUID for uniqueness\n",
    "            \"text\": full_text,\n",
    "            \"source\": \"Card Database\",\n",
    "            \"card_name\": c[\"name\"],\n",
    "            \"manaCost\": c.get(\"manaCost\", \"\"),\n",
    "            \"types\": \", \".join(c.get(\"types\", [])),       # FIXED: stringify list\n",
    "            \"subtypes\": \", \".join(c.get(\"subtypes\", [])), # FIXED: stringify list\n",
    "            \"keywords\": \", \".join(c.get(\"keywords\", [])), # FIXED: stringify list\n",
    "            \"rarity\": c.get(\"rarity\", \"\")\n",
    "        })\n",
    "\n",
    "    print(f\"Loaded {len(docs)} cards from {path}\")\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "e04fb8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- HELPER CHUNK TEXT --------\n",
    "def chunk_text(text, chunk_size=CHUNK_SIZE):\n",
    "    \"\"\"Split text into smaller chunks so embeddings don't get too big.\"\"\"\n",
    "    sentences = re.split(r'(?<=[.!?]) +', text)\n",
    "    chunks = []\n",
    "    current = []\n",
    "    length = 0\n",
    "\n",
    "    for s in sentences:\n",
    "        tokens = len(s.split())\n",
    "        if length + tokens > chunk_size:\n",
    "            chunks.append(\" \".join(current))\n",
    "            current = [s]\n",
    "            length = tokens\n",
    "        else:\n",
    "            current.append(s)\n",
    "            length += tokens\n",
    "    if current:\n",
    "        chunks.append(\" \".join(current))\n",
    "\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "57272cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- HELPER BUILD INDEX --------\n",
    "def build_index():\n",
    "    \"\"\"Create ChromaDB collection from rules + card data.\"\"\"\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "    print(\"Loading rules...\")\n",
    "    rules = load_rules(RULES_FILE)\n",
    "\n",
    "    print(\"Loading cards...\")\n",
    "    cards = load_cards(CARDS_FILE)  # add this\n",
    "\n",
    "    all_docs = rules + cards  # merge datasets\n",
    "\n",
    "    texts, metas, ids = [], [], []\n",
    "\n",
    "    for d in all_docs:\n",
    "        chunks = chunk_text(d[\"text\"])\n",
    "        for i, ch in enumerate(chunks):\n",
    "            texts.append(ch)\n",
    "            metas.append(d)\n",
    "            ids.append(f\"{d['id']}_{i}\")\n",
    "\n",
    "    if not texts:\n",
    "        raise ValueError(\"No valid chunks found to embed.\")\n",
    "\n",
    "    print(f\"Total chunks: {len(texts)}\")\n",
    "\n",
    "    # Create embeddings\n",
    "    embeddings = client.embeddings.create(model=EMBED_MODEL, input=texts)\n",
    "    vecs = [d.embedding for d in embeddings.data]\n",
    "\n",
    "    # Initialize Chroma client\n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_DB_DIR)\n",
    "\n",
    "    # Drop old collection (clean rebuild)\n",
    "    try:\n",
    "        chroma_client.delete_collection(\"mtg_data\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    collection = chroma_client.get_or_create_collection(name=\"mtg_data\")\n",
    "\n",
    "    # Add to Chroma\n",
    "    collection.add(\n",
    "        ids=ids,\n",
    "        embeddings=vecs,\n",
    "        documents=texts,\n",
    "        metadatas=metas\n",
    "    )\n",
    "\n",
    "    print(\"Index built and saved with ChromaDB!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "94b43337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- HELPER SEARCH INDEX --------\n",
    "def search_index(query, top_k=TOP_K):\n",
    "    \"\"\"Search ChromaDB for relevant rule chunks.\"\"\"\n",
    "    query = query.strip()\n",
    "    if not query:\n",
    "        raise ValueError(\"Empty query provided.\")\n",
    "\n",
    "    # client = OpenAI()\n",
    "    emb = client.embeddings.create(model=EMBED_MODEL, input=[query])\n",
    "    vec = emb.data[0].embedding\n",
    "\n",
    "    chroma_client = chromadb.PersistentClient(path=CHROMA_DB_DIR)\n",
    "    collection = chroma_client.get_or_create_collection(name=\"mtg_rules\")\n",
    "\n",
    "    results = collection.query(query_embeddings=[vec], n_results=top_k)\n",
    "\n",
    "    docs = []\n",
    "    for i, doc in enumerate(results[\"documents\"][0]):\n",
    "        docs.append({\n",
    "            \"text\": doc,\n",
    "            \"meta\": results[\"metadatas\"][0][i]\n",
    "        })\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d9f62d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- HELPER GENERATE SUBQUERIES --------\n",
    "def generate_subqueries(query, n=10):\n",
    "    \"\"\"Chain of Thought decomposition function. Use the LLM to break a user query into smaller sub-questions.\"\"\"\n",
    "    #client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    prompt = f\"\"\"\n",
    "    Break down the following Magic: The Gathering rules question into {n} smaller, \n",
    "    more specific sub-questions that cover timing, abilities, rules interactions, \n",
    "    and possible edge cases. Return them as a numbered list.\n",
    "\n",
    "    Original Question: {query}\n",
    "    \"\"\"\n",
    "    resp = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        temperature=0.2,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert MTG judge assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    text = resp.choices[0].message.content\n",
    "    subqueries = [line.strip(\"0123456789. \") for line in text.splitlines() if line.strip()]\n",
    "    return subqueries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce7ab0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- HELPER ANSWER WITH SUBQUERIES --------\n",
    "def answer_with_subqueries(query):\n",
    "    \"\"\"Break question into subqueries, search index for each, and generate final answer.\"\"\"\n",
    "    # Step 1: Get subqueries\n",
    "    subqueries = generate_subqueries(query, n=10)\n",
    "    # print(\"Subqueries:\", subqueries)\n",
    "\n",
    "    # Step 2: Collect context from all subqueries\n",
    "    all_context = []\n",
    "    for sq in subqueries:\n",
    "        results = search_index(sq, top_k=5)  # use your existing search_index\n",
    "        for i, r in enumerate(results, 1):\n",
    "            all_context.append(f\"Subquery: {sq}\\n- Source: {r['meta'].get('source', '')}\\n- Text: {r['text']}\")\n",
    "\n",
    "    context = \"\\n\\n\".join(all_context)\n",
    "\n",
    "    response_format = \"\"\"\n",
    "    Please provide a structured answer with the following format:\n",
    "    - Question: [a rephrased version of the user question in the most clear form]\n",
    "    - Short Answer: [short summary answer, this sentence should always start with a Yes or No if possible]\n",
    "    - Full Explanation: [detailed reasoning with rules and card interactions]\n",
    "    - Sources: [cite the rules used for the response and also add the full text of the cards involved or that were most relevant]\n",
    "    \"\"\"\n",
    "\n",
    "    #! temporal reply format for benchmarks\n",
    "    # response_format = \"Respond only with a Yes or No answer. Nothing more should be added\"\n",
    "\n",
    "    # Step 3: Ask LLM for final structured response\n",
    "    system_prompt = f\"\"\"\n",
    "    You are an expert Magic: The Gathering judge assistant.\n",
    "    A user has a question about card interactions or rules.\n",
    "\n",
    "    Use these sources (rules + card texts):\n",
    "    {context}\n",
    "\n",
    "    Answer format:\n",
    "    {response_format}\n",
    "    \"\"\"\n",
    "\n",
    "    user_prompt = f\"\"\"\n",
    "    The question from the user is:\n",
    "    {query}\n",
    "    \"\"\"\n",
    "    \n",
    "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
    "    resp = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        temperature=0, # lowering temperature for more accurate and consistant response according to rules\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    #* SECONDARY JUDGE VERIFICATION\n",
    "    verification_system_prompt = f\"\"\"\n",
    "    You are an expert Magic: The Gathering high judge.\n",
    "    You will be given:\n",
    "\n",
    "    - A user’s question\n",
    "    - A judge’s ruling on that question\n",
    "    - All the context provided by the judge\n",
    "\n",
    "    Your task is to carefully review and analyze the information. Then, determine whether the context adequately supports the judge’s ruling. Based on your analysis, you may either accept or deny the ruling.\n",
    "\n",
    "    Your response should follow this format:\n",
    "\n",
    "    - If you agree with the ruling, respond: Accepted\n",
    "    - If you disagree with the ruling, respond: Denied, [include context explaining the reason for denial]\n",
    "\n",
    "    The original user question is:\n",
    "    {query}\n",
    "    \"\"\"\n",
    "\n",
    "    judge_prompt = f\"\"\"\n",
    "    The context brought by the initial ruling judge was:\n",
    "    {context}\n",
    "\n",
    "    The final response from the initial judge was:\n",
    "    {resp.choices[0].message.content}\n",
    "    \"\"\"\n",
    "\n",
    "    client = OpenAI(api_key=OPENAI_API_KEY) # new model initialization for new judge\n",
    "    resp2 = client.chat.completions.create(\n",
    "        model=CHAT_MODEL,\n",
    "        temperature=0, # lowering temperature for more accurate and consistant response according to rules\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": verification_system_prompt},\n",
    "            {\"role\": \"user\", \"content\": judge_prompt}\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    judge2_response = resp2.choices[0].message.content\n",
    "\n",
    "    if judge2_response == \"Accepted\":\n",
    "        return resp.choices[0].message.content\n",
    "    else:\n",
    "        return f\"\"\"\n",
    "        We’re sorry, our virtual judges were unable to reach an agreement on a final response to your question.\n",
    "\n",
    "        Reason: The original judge’s ruling was: {judge2_response}\n",
    "\n",
    "        Please try asking your question again, this time with clearer wording to help us provide a more definitive answer.\n",
    "        \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "07ad31bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading rules...\n",
      "Loading cards...\n",
      "Loaded 90 cards from ./clean-standard-cards.json\n",
      "Total chunks: 91\n",
      "Index built and saved with ChromaDB!\n"
     ]
    }
   ],
   "source": [
    "# -------- BUILDING INDEX --------\n",
    "build_index()  # only first time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c76f5f",
   "metadata": {},
   "source": [
    "# Single testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "46b4e3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_question = \"Someone is playing Flashfreeze on one of my spells, Can I play Aven Interrupter on top of Flashfreeze so my initial spell can be resolved?. Right answer: Yes. Response: No\"\n",
    "response = answer_with_subqueries(single_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "edabb9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Question: Can I play Aven Interrupter on top of Flashfreeze to allow my original spell to resolve?\n",
      "- Short Answer: Yes.\n",
      "- Full Explanation: In this scenario, you can respond to Flashfreeze by casting Aven Interrupter. Flashfreeze is an instant that counters a target spell that is blue, and it goes on the stack above the original spell. When you cast Aven Interrupter, it will also go on the stack above Flashfreeze. However, Aven Interrupter has the ability to counter a spell, but it can only do so if it resolves before Flashfreeze. If Aven Interrupter resolves successfully, it can counter Flashfreeze, allowing your original spell to resolve. If Flashfreeze resolves first, it will counter your original spell. Therefore, the timing of casting Aven Interrupter is crucial, and you must ensure it resolves before Flashfreeze does.\n",
      "- Sources: Comprehensive Rules, specifically regarding the stack and spell resolution.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd13c42",
   "metadata": {},
   "source": [
    "# Multiple testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9c00ab1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct answers: 39/45\n",
      "Does scry let you look at cards and choose to put some on top or bottom of your library?. Right answer: Yes. Response: No\n",
      "Can there be infinite or multiple cleanup steps triggered by effects like Kozilek plus discard effects?. Right answer: Yes. Response: No\n",
      "Are continuous effects applied in a specific layered system, such as type-changing, ability additions, P/T changes, in numbered order?. Right answer: Yes. Response: No\n",
      "Are special actions like playing a land or turning a face-down creature face-up things opponents cannot respond to?. Right answer: Yes. Response: No\n",
      "If I imprint Time Walk on Panoptic Mirror, do I get infinite turns?. Right answer: Yes. Response: No\n",
      "Someone is playing Flashfreeze on one of my spells, Can I play Aven Interrupter on top of Flashfreeze so my initial spell can be resolved?. Right answer: Yes. Response: No\n"
     ]
    }
   ],
   "source": [
    "with open(\"easy-questions.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    easy_questions = json.load(f)\n",
    "with open(\"hard-questions.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    hard_questions = json.load(f)\n",
    "with open(\"own-questions.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    own_questions = json.load(f)\n",
    "\n",
    "all_questions = easy_questions + hard_questions + own_questions\n",
    "\n",
    "correct_answers = 0\n",
    "wrong_answered_questions = []\n",
    "\n",
    "for question in all_questions:\n",
    "    # response = answer_question(question[\"text\"])\n",
    "    response = answer_with_subqueries(question[\"text\"])\n",
    "    # response = answer_with_subqueries(question.text)\n",
    "    if response == question[\"answer\"]:\n",
    "        correct_answers += 1\n",
    "    else:\n",
    "        wrong_answered_questions.append(f\"{question[\"text\"]}. Right answer: {question[\"answer\"]}. Response: {response}\")\n",
    "\n",
    "print(f\"correct answers: {correct_answers}/{len(all_questions)}\")\n",
    "for each_wrong_question in wrong_answered_questions:\n",
    "    print(each_wrong_question)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46d4e00",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d812b32e",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Test: No temperature set and no subqueries.\n",
    "\n",
    "### Correct answers: 30/45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b2a0e5",
   "metadata": {},
   "source": [
    "## Test: Temperature set to 0.1 and no subqueries.\n",
    "\n",
    "### Correct answers: 35/45"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd33259b",
   "metadata": {},
   "source": [
    "## Test: Temperature set to 0.1 and 5 subqueries.\n",
    "\n",
    "### Correct answers: 37/45\n",
    "\n",
    "#### Incorrect answer to:\n",
    "- Does scry let you look at cards and choose to put some on top or bottom of your library?\n",
    "- If you draw more than seven cards, can you keep them all if no other effect limits your hand size?\n",
    "- Can there be infinite or multiple cleanup steps triggered by effects like Kozilek plus discard effects?\n",
    "- If a creature phases out and back in, does it lose summoning sickness if it had it before?\n",
    "- Are special actions like playing a land or turning a face-down creature face-up things opponents cannot respond to?\n",
    "- If I imprint Time Walk on Panoptic Mirror, do I get infinite turns?\n",
    "- I am being attacked by Axebane Ferox and I declare Aegis Turtle as a blocker. But before assigning damage, I play Bounce Off on Aegis Turtle. Do I still receive 4 damage from Agonasaur Rex?\n",
    "- Someone is playing Flashfreeze on one of my spells, Can I play Aven Interrupter on top of Flashfreeze so my initial spell can be resolved?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf5de3c",
   "metadata": {},
   "source": [
    "## Test: Temperature set to 0 and 10 subqueries.\n",
    "\n",
    "- 8 minutes for 45 queries (10 seconds per query)\n",
    "\n",
    "### Correct answers: 39/45\n",
    "\n",
    "#### Incorrect answer to:\n",
    "- Does scry let you look at cards and choose to put some on top or bottom of your library?. Right answer: Yes. Response: No\n",
    "- Can there be infinite or multiple cleanup steps triggered by effects like Kozilek plus discard effects?. Right answer: Yes. Response: No\n",
    "- Are continuous effects applied in a specific layered system, such as type-changing, ability additions, P/T changes, in numbered order?. Right answer: Yes. Response: No\n",
    "- Are special actions like playing a land or turning a face-down creature face-up things opponents cannot respond to?. Right answer: Yes. Response: No\n",
    "- If I imprint Time Walk on Panoptic Mirror, do I get infinite turns?. Right answer: Yes. Response: No\n",
    "- Someone is playing Flashfreeze on one of my spells, Can I play Aven Interrupter on top of Flashfreeze so my initial spell can be resolved?. Right answer: Yes. Response: No"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
